{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Plot-JHU-Data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/fJxltsHgOOuwUdpalYMf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\"\"\"\n","In this notebook, we aim to plot/show the raw JHU covid data, as well as the JHU covid data after some preprocessing in STAN\n","\"\"\""],"metadata":{"id":"Hk7x5LylHuz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","% cd /content/gdrive/My Drive/Github/\"CS 499 - SPRING 2022\"/\"0. Data Analysis\"\n","! pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndxA_CMY-98u","executionInfo":{"status":"ok","timestamp":1644419547084,"user_tz":360,"elapsed":17863,"user":{"displayName":"Andrew Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15265478926702059943"}},"outputId":"ffdb4ac6-6b39-473f-ce65-73babbbfa497"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Github/CS 499 - SPRING 2022/0. Data Analysis\n","/content/gdrive/My Drive/Github/CS 499 - SPRING 2022/0. Data Analysis\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Plot raw JHU data\n","\"\"\"\n","\n","###################################################################################################################\n","###################################################################################################################\n","# Download raw data with minimal preprocessing - cell takes 40 seconds to run\n","###################################################################################################################\n","###################################################################################################################\n","\n","# Import needed libraries\n","import pandas as pd \n","from datetime import datetime\n","\n","# Get list of dates between start_date and end_date formatted as Python strings\n","dateList = []\n","start_date = '2020-04-12'\n","end_date = '2022-01-24'\n","date_list = pd.date_range(start_date, end_date).strftime(\"%m-%d-%Y\")\n","\n","# Base url to which we will append onto date + \".csv\" to download data from\n","url_base = f\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/\"\n","\n","# List of dataframes\n","data_list = [] # != date_list\n","for date in date_list:\n","  df = pd.read_csv(url_base + str(date) + \".csv\") \n","  df.loc[:, 'date_today'] = datetime.strptime(date, \"%m-%d-%Y\")\n","  data = df.rename(columns={\"date_today\": \"date_today\", \"Province_State\": \"province_state\", \"Country_Region\": \"country_region\", \"Last_Update\": \"last_update\", \n","                                \"Lat\": \"latitude\", \"Long_\": \"longitude\", 'Confirmed': \"confirmed\", 'Deaths': \"deaths\", 'Recovered': \"recovered\",\n","                                'Active': \"active\", 'FIPS': \"fips\", 'Incident_Rate': \"incident_rate\", \n","                                \"Total_Test_Results\": \"total_test_results\", \"People_Hospitalized\": \"people_hospitalized\", \n","                                'Case_Fatality_Ratio': \"case_fatality_ratio\", 'UID': \"uid\", 'ISO3': \"iso3\", \n","                                'Testing_Rate': \"testing_rate\", 'Hospitalization_Rate': \"hospitalization_rate\"})\n","  data_list.append(data)\n","\n","# Code showing that first 18 days of data in this date range have an extra and unnecessary row called \"Recovered\"\n","# for i in range(len(data_list)):\n","#   thing = data_list[i]\n","#   if len(thing) != 58:\n","#     print(i, len(thing))\n","# set1 = set(data_list[17].state.unique())\n","# set2 = set(data_list[18].state.unique())\n","# set1-set2\n","\n","# Take 653 dataframes in data_list each with 58 rows of data, and concatenate them into 1 giant dataframe\n","data = pd.concat(data_list, axis=0)\n","\n","# Remove the extra \"Recovered\" row\n","data = data[data.province_state != \"Recovered\"] # 58 states x 653 days between = 37874 rows of data \n","\n","# Save data as CSV file\n","data.to_csv('./data/jhu_raw_data.csv')"],"metadata":{"id":"3dKfyNdg_aja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###################################################################################################################\n","###################################################################################################################\n","# Actually do the plotting for JHU raw data - cell takes 2 minutes 32 seconds to run\n","###################################################################################################################\n","###################################################################################################################\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","data = data.fillna(0)\n","\n","state_list = data.province_state.unique()\n","columns_list = []\n","for column in data.columns:\n","  columns_list.append(column)\n","  # ['province_state', 'country_region', 'last_update', 'latitude', 'longitude', \n","  #   'confirmed', 'deaths', 'recovered', 'active', \n","  #   'fips', 'incident_rate', 'People_Tested', \n","  #   'people_hospitalized', 'Mortality_Rate', 'uid', 'iso3', \n","  #   'testing_rate', 'hospitalization_rate', 'date_today', 'total_test_results', 'case_fatality_ratio']\n","columns_of_interest = ['confirmed', 'deaths', 'recovered', 'active', 'incident_rate', 'People_Tested', 'people_hospitalized', 'Mortality_Rate', \n","                       'testing_rate', 'hospitalization_rate', 'total_test_results', 'case_fatality_ratio']\n","\n","\n","# Plot confirmed cases\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].confirmed.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Confirmed: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/confirmed.png\")\n","\n","# Plot deaths\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].deaths.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Deaths: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/deaths.png\")\n","\n","# Plot recovered\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].recovered.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Recovered: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/recovered.png\")\n","\n","# Plot active\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].active.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Active: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/active.png\")\n","\n","# Plot incident rate\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].incident_rate.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Incident Rate: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/incident_rate.png\")\n","\n","# Plot people tested\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].People_Tested.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"People Tested: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/people_tested.png\")\n","\n","# Plot people hospitalized\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].people_hospitalized.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"People Hospitalized: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/people_hospitalized.png\")\n","\n","# Plot Mortality Rate\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].Mortality_Rate.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Mortality Rate: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/mortality_rate.png\")\n","\n","# Plot testing rate\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].testing_rate.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Testing Rate: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/testing_rate.png\")\n","\n","# Plot Hospitalization Rate\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].hospitalization_rate.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Hospitalization Rate: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/hospitalization_rate.png\")\n","\n","# Plot total_test_results\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].total_test_results.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Total Test Results: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/total_test_results.png\")\n","\n","# Plot Case Fatality Ratio\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","x = np.arange(653)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.province_state == curr_state_name].case_fatality_ratio.to_list()\n","  axs[idx0, idx1].plot(x, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Case fatality ratio: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_raw_data/case_fatality_ratio.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19O2Jjn974meMWdgalDEnmq4nf0rxzaF1"},"id":"tP1qhbkI3N3z","executionInfo":{"status":"ok","timestamp":1644252221269,"user_tz":360,"elapsed":152820,"user":{"displayName":"Andrew Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15265478926702059943"}},"outputId":"3e76d001-2a9b-4e00-bff3-114b76000ece"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["\"\"\"\n","Plot STAN's data/variables\n","\"\"\"\n","\n","###################################################################################################################\n","###################################################################################################################\n","# Download raw data with minimal preprocessing - cell takes 40 seconds to run\n","# Copied code for downloading+some preprocessing of data from STAN's data_downloader.py and utils.py to this cell\n","###################################################################################################################\n","###################################################################################################################\n","\n","import pandas as pd\n","import io\n","import logging\n","import requests\n","import pickle\n","\n","from datetime import datetime\n","from multiprocessing import Pool\n","\n","import urllib3\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","def check_url(url):\n","    \"\"\"\n","    Function to check the existence of ulr\n","    :param url:\n","    :return:\n","    \"\"\"\n","    request = requests.get(url, verify=False)\n","    if request.status_code < 400:\n","        return True\n","    else:\n","        logging.info(f\"URL for {url.split('/')[-1]} does not exist!\")\n","        return False\n","\n","def download_data(url):\n","    \"\"\"\n","    Function that downloads the csv files from Github\n","    :param url: url of the csv file\n","    :type url: str\n","    :return: content of csv file\n","    :rtype: pandas.DataFrame\n","    \"\"\"\n","    if check_url(url):\n","        x = requests.get(url=url, verify=False).content\n","        df = pd.read_csv(io.StringIO(x.decode('utf8')))\n","        return df\n","\n","\n","class GenerateTrainingData:\n","\n","    def __init__(self):\n","        self.df = None\n","        self.url_base = f\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/\" \\\n","                        f\"csse_covid_19_daily_reports_us/\"\n","        self.common_columns = [\"state\", \"latitude\", \"longitude\", \"fips\", \"date_today\", \"confirmed\", \"deaths\",\n","                               \"recovered\",\n","                               \"active\", \"hospitalization\"]\n","\n","    def download_single_file(self, date):\n","        url = self.url_base + \"/\" + f\"{date}.csv\"\n","        data = download_data(url=url)\n","        if data is None:\n","            logging.info(f\"{date}.csv doesn't not exists or failed to be downloaded!\")\n","            return None\n","        data.loc[:, 'date_today'] = datetime.strptime(date, \"%m-%d-%Y\")\n","        data = data.rename(columns={\"Province_State\": \"state\", \"Lat\": \"latitude\", \"Long_\": \"longitude\",\n","                                    'Confirmed': \"confirmed\", 'Deaths': \"deaths\", 'Recovered': \"recovered\",\n","                                    'Active': \"active\", 'FIPS': \"fips\", \"People_Hospitalized\": \"hospitalization\"}) \\\n","            .dropna(subset=['fips'])\n","        data.loc[:, \"fips\"] = data['fips'].astype(int)\n","        data = data[self.common_columns].fillna(0)\n","        return data\n","\n","    def download_jhu_data(self, start_time, end_time):\n","        date_list = pd.date_range(start_time, end_time).strftime(\"%m-%d-%Y\")\n","\n","        data = Pool().map(self.download_single_file, date_list)\n","        print('Finish download')\n","\n","        # Save object to pickle for later use in debugging\n","        filehandler = open(\"./data/jhu_debugging_data.pickle\", 'wb') \n","        pickle.dump(data, filehandler)\n","\n","        data = [x for x in data if x is not None]\n","        data = pd.concat(data, axis=0)\n","\n","        data.loc[:, 'date_today'] = pd.to_datetime(data['date_today'])\n","        df = []\n","        for fips in data['fips'].unique():\n","            temp = data[data['fips'] == fips].sort_values('date_today')\n","            temp.loc[:, \"new_cases\"] = temp['confirmed'].copy()\n","            # transform to daily cases\n","            for col in [\"new_cases\", \"deaths\", \"hospitalization\"]:\n","                t = temp[col].copy().sort_values().to_numpy()\n","                t[1:] = t[1:] - t[:-1]\n","                temp = temp.iloc[1:]\n","                temp.loc[:, col] = t[1:]\n","            df.append(temp)\n","        df = pd.concat(df, axis=0)\n","\n","        df.to_pickle('./data/jhu_processed_data.pickle')\n","        return df\n","\n","jhu_processed_data = GenerateTrainingData().download_jhu_data('2020-04-12', '2022-01-24')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NrFo5c3s_dRj","executionInfo":{"status":"ok","timestamp":1644419684636,"user_tz":360,"elapsed":104894,"user":{"displayName":"Andrew Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15265478926702059943"}},"outputId":"875a8e22-d4b2-4802-b9c7-01fc5e32d1a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finish download\n"]}]},{"cell_type":"code","source":["# Some analysis of the JHU debugging data pickle to see why \"JHU_processed_data.pickle\" doesn't have 653 days of data for every state \n","#   (653 = number of days between 2020-04-12 and 2022-01-24, inclusive of both start and end date)\n","\n","# Get set of dates from raw data \n","start_date = '2020-04-12'\n","end_date = '2022-01-24'\n","date_list = pd.date_range(start_date, end_date).strftime(\"%Y-%m-%d\")\n","jhu_raw_set_dates = set(date_list)\n","print(\"Length of raw dataset dates:\", len(jhu_raw_set_dates))\n","\n","# Get dates from processed data \n","jhu_processed_np_datetime_strings = np.datetime_as_string(jhu_processed_data.date_today.unique(), unit='D')\n","jhu_processed_set_dates = set(jhu_processed_np_datetime_strings)\n","print(\"Length of processed dataset dates:\", len(jhu_processed_set_dates))\n","\n","# Get difference in dates (what dates are present in the raw data but ARENT present in the processed data)\n","print(\"Difference in dates:\", jhu_raw_set_dates - jhu_processed_set_dates)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ExNgv4tPPwd","executionInfo":{"status":"ok","timestamp":1644263586066,"user_tz":360,"elapsed":206,"user":{"displayName":"Andrew Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15265478926702059943"}},"outputId":"767501f6-6d99-4d38-bc9f-69066990565f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of raw dataset dates: 653\n","Length of processed dataset dates: 650\n","Difference in dates: {'2020-04-14', '2020-04-13', '2020-04-12'}\n"]}]},{"cell_type":"code","source":["# Debug why the processed data is missing data from 3 dates\n","\n","import pickle \n","\n","filehandler = open(\"./data/jhu_debugging_data.pickle\", 'rb')\n","data = pickle.load(filehandler) # so far so good, seems like there are 653 dataframes in \"data\"\n","\n","for i in range(len(data)):\n","  curr_df = data[i]\n","  if (curr_df.shape != (58, 10)):\n","    print(\"Shape not consistent in data:\", i, curr_df.shape) # seems like 2020-04-12 is missing data from 1 of 58 states/provinces\n","\n","data = [x for x in data if x is not None] # still so far so good, 653 items in data\n","data = pd.concat(data, axis=0) # concatenates everything in the list into a giant dataframe\n","print(data.shape) # 37873 = 653 days * 58 rows of data per day - 1 location/day missing (April 12th, 2020)\n","\n","data.loc[:, 'date_today'] = pd.to_datetime(data['date_today']) # converts dates to datetime objects?\n","print(data.shape) # 37873 = 653 days * 58 rows of data per day - 1 location/day missing (April 12th, 2020)\n","\n","print(\"length of data['fips'].unique():\", len(data['fips'].unique())) # 60 fips codes\n","print(\"unique fips codes:\", data['fips'].unique())\n","\n","df = []\n","for fips in data['fips'].unique():\n","    temp = data[data['fips'] == fips].sort_values('date_today')\n","\n","    # print(\"temp.shape before \", temp.shape) # (653, 10)\n","\n","    temp.loc[:, \"new_cases\"] = temp['confirmed'].copy()\n","\n","    print(\"temp.shape during, part1\", temp.shape)\n","\n","    # transform to daily cases\n","    for col in [\"new_cases\", \"deaths\", \"hospitalization\"]:\n","        t = temp[col].copy().sort_values().to_numpy()\n","        t[1:] = t[1:] - t[:-1]\n","        temp = temp.iloc[1:]\n","        temp.loc[:, col] = t[1:]\n","    \n","    # print(\"temp.shape after\", temp.shape) # (650, 11)\n","    \n","    df.append(temp)\n","df = pd.concat(df, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdwWSvJPv0vl","executionInfo":{"status":"ok","timestamp":1644264643731,"user_tz":360,"elapsed":2460,"user":{"displayName":"Andrew Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15265478926702059943"}},"outputId":"d8105df8-ac90-4419-d454-ff5ee278c618"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape not consistent in data: 0 (57, 10)\n","(37873, 10)\n","(37873, 10)\n","length of data['fips'].unique(): 60\n","unique fips codes: [    1     2     4     5     6     8     9    10   888    11    12    13\n","   999    66    15    16    17    18    19    20    21    22    23    24\n","    25    26    27    28    29    30    31    32    33    34    35    36\n","    37    38    39    40    41    42    72    44    45    46    47    48\n","    49    50    51    53    54    55    56    60    69 88888 99999    78]\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (1, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (1, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_column(ilocs[0], value, pi)\n"]},{"output_type":"stream","name":"stdout","text":["temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (653, 11)\n","temp.shape during, part1 (652, 11)\n","temp.shape during, part1 (652, 11)\n","temp.shape during, part1 (652, 11)\n"]}]},{"cell_type":"code","source":["# Show that there are 650 records of data for most states, with a few exceptions (Diamond Princess, Grand Princess, and Virgin Islands which each have 649 records of data)\n","for state in jhu_processed_data.state.unique():\n","  num_records_for_state = len(jhu_processed_data[jhu_processed_data.state == state])\n","  print(state, num_records_for_state)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVPqasBiDMQx","executionInfo":{"status":"ok","timestamp":1644419908186,"user_tz":360,"elapsed":443,"user":{"displayName":"Andrew Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15265478926702059943"}},"outputId":"bece9ebc-82b4-4088-bdd1-94b93b0837f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alabama 650\n","Alaska 650\n","Arizona 650\n","Arkansas 650\n","California 650\n","Colorado 650\n","Connecticut 650\n","Delaware 650\n","District of Columbia 650\n","Florida 650\n","Georgia 650\n","Guam 650\n","Hawaii 650\n","Idaho 650\n","Illinois 650\n","Indiana 650\n","Iowa 650\n","Kansas 650\n","Kentucky 650\n","Louisiana 650\n","Maine 650\n","Maryland 650\n","Massachusetts 650\n","Michigan 650\n","Minnesota 650\n","Mississippi 650\n","Missouri 650\n","Montana 650\n","Nebraska 650\n","Nevada 650\n","New Hampshire 650\n","New Jersey 650\n","New Mexico 650\n","New York 650\n","North Carolina 650\n","North Dakota 650\n","Ohio 650\n","Oklahoma 650\n","Oregon 650\n","Pennsylvania 650\n","Puerto Rico 650\n","Rhode Island 650\n","South Carolina 650\n","South Dakota 650\n","Tennessee 650\n","Texas 650\n","Utah 650\n","Vermont 650\n","Virginia 650\n","Washington 650\n","West Virginia 650\n","Wisconsin 650\n","Wyoming 650\n","American Samoa 650\n","Northern Mariana Islands 650\n","Diamond Princess 649\n","Grand Princess 649\n","Virgin Islands 649\n"]}]},{"cell_type":"code","source":["###################################################################################################################\n","###################################################################################################################\n","# Actually do the plotting for JHU processed data\n","###################################################################################################################\n","###################################################################################################################\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","state_list = jhu_processed_data.state.unique()\n","\n","# jhu_processed_data.columns\n","# Index(['state', 'latitude', 'longitude', 'fips', 'date_today', 'confirmed',\n","#        'deaths', 'recovered', 'active', 'hospitalization', 'new_cases'],\n","#       dtype='object')\n","columns_of_interest = ['confirmed', 'deaths', 'recovered', 'active', 'hospitalization', 'new_cases']\n","\n","data = jhu_processed_data\n","\n","x1 = np.arange(650) # For most states/locations\n","x2 = np.arange(649) # For Diamond Princess, Grand Princess, and Virgin Islands\n","\n","# Plot confirmed cases\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.state == curr_state_name].confirmed.to_list()\n","  if (state_list[i] != 'Diamond Princess' and state_list[i] != 'Grand Princess' and state_list[i] != 'Virgin Islands'):\n","    axs[idx0, idx1].plot(x1, data_of_interest)\n","  else:\n","    axs[idx0, idx1].plot(x2, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Confirmed: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_processed_data/confirmed.png\")\n","\n","# Plot deaths\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.state == curr_state_name].deaths.to_list()\n","  if (state_list[i] != 'Diamond Princess' and state_list[i] != 'Grand Princess' and state_list[i] != 'Virgin Islands'):\n","    axs[idx0, idx1].plot(x1, data_of_interest)\n","  else:\n","    axs[idx0, idx1].plot(x2, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Deaths: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_processed_data/deaths.png\")\n","\n","# Plot recovered\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.state == curr_state_name].recovered.to_list()\n","  if (state_list[i] != 'Diamond Princess' and state_list[i] != 'Grand Princess' and state_list[i] != 'Virgin Islands'):\n","    axs[idx0, idx1].plot(x1, data_of_interest)\n","  else:\n","    axs[idx0, idx1].plot(x2, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Recovered: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_processed_data/recovered.png\")\n","\n","# Plot active cases\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.state == curr_state_name].active.to_list()\n","  if (state_list[i] != 'Diamond Princess' and state_list[i] != 'Grand Princess' and state_list[i] != 'Virgin Islands'):\n","    axs[idx0, idx1].plot(x1, data_of_interest)\n","  else:\n","    axs[idx0, idx1].plot(x2, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Active: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_processed_data/active.png\")\n","\n","# Plot hospitalization\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.state == curr_state_name].hospitalization.to_list()\n","  if (state_list[i] != 'Diamond Princess' and state_list[i] != 'Grand Princess' and state_list[i] != 'Virgin Islands'):\n","    axs[idx0, idx1].plot(x1, data_of_interest)\n","  else:\n","    axs[idx0, idx1].plot(x2, data_of_interest)\n","  axs[idx0, idx1].set_title(\"Hospitalization: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_processed_data/hospitalization.png\")\n","\n","# Plot new_cases\n","fig, axs = plt.subplots(29, 2)\n","fig.set_size_inches(8, 232)\n","for i in range(len(state_list)): \n","  idx0 = i // 2\n","  idx1 = i % 2\n","  curr_state_name = state_list[i]\n","  data_of_interest = data[data.state == curr_state_name].new_cases.to_list()\n","  if (state_list[i] != 'Diamond Princess' and state_list[i] != 'Grand Princess' and state_list[i] != 'Virgin Islands'):\n","    axs[idx0, idx1].plot(x1, data_of_interest)\n","  else:\n","    axs[idx0, idx1].plot(x2, data_of_interest)\n","  axs[idx0, idx1].set_title(\"New cases: \" + curr_state_name)\n","plt.savefig(\"./plots/JHU_processed_data/new_cases.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17dXh0gctTwm-BO6lZoBg2ntrbNqu9ie_"},"id":"9-Muf_agLfDa","executionInfo":{"status":"ok","timestamp":1644420297936,"user_tz":360,"elapsed":63694,"user":{"displayName":"Andrew Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15265478926702059943"}},"outputId":"58e63c0d-1735-4c3b-f64c-79ed98dc8044"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}